
\chapter{矩阵与向量}
\label{chap:matrix}

通俗地讲，矩阵就是$n\times m$个东西排列成一个$n\times m$的矩形阵列。在数学上，阵列里的东西通常是各种各样的“数”，实数、复数、函数等。

\section{行列式}
\label{sec:determinant}

行列式(Determinant)是针对$n\times n$的方阵的概念，方阵$A$的行列式通常用$\left| A\right|$或者$\det(A)$表示。二阶方阵的行列式为
\begin{align*}
  \begin{vmatrix}
    a_{11} & a_{12}\\
    a_{21} & a_{22}
  \end{vmatrix}
             \equiv a_{11}a_{22} - a_{12}a_{21}
\end{align*}

三阶方阵的行列式为
\begin{align*}
  \begin{vmatrix}
    a_{11} & a_{12} & a_{13}\\
    a_{21} & a_{22} & a_{23}\\
    a_{31} & a_{32} & a_{33}
  \end{vmatrix}\equiv
   a_{11}\begin{vmatrix} a_{22} & a_{23}\\ a_{32} & a_{33} \end{vmatrix}
  -a_{21}\begin{vmatrix} a_{12} & a_{13}\\ a_{32} & a_{33} \end{vmatrix}
  +a_{31}\begin{vmatrix} a_{12} & a_{13}\\ a_{22} & a_{23} \end{vmatrix}
\end{align*}

同样可以递归地用$n$阶方阵的行列式定义$n+1$阶方阵的行列式。若要深入系统地学习了解高阶矩阵的，请移步参考高等代数、矩阵分析等相关教材。

\begin{example}[萨吕法则，Sarrus' Rule，Sarrus' Scheme]
  将$3\times 3$的矩阵
  \begin{align*}
    M =
    \begin{pmatrix}
      a_{11} & a_{12} & a_{13}\\
      a_{21} & a_{22} & a_{23}\\
      a_{31} & a_{32} & a_{33}
    \end{pmatrix}
  \end{align*}
  按图~\ref{fig:Sarrus'-rule}扩充为$3\times 5$的矩阵并沿对角线作出辅助线：
  \begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1]
      \fill[color=blue!10](-.5,.5)rectangle(2.5,-2.5);
      \foreach \x/\y/\v/\i in{0/0/11/11, 1/0/12/12, 2/0/13/13, 3/0/11/e11, 4/0/12/e12,
                              0/1/21/21, 1/1/22/22, 2/1/23/23, 3/1/21/e21, 4/1/22/e22,
                              0/2/31/31, 1/2/32/32, 2/2/33/33, 3/2/31/e31, 4/2/32/e32}{
        \node(N\i) at (\x, -\y){$a_{\v}$};
      }
      \foreach \a/\b/\c in {11/22/33,12/23/e31,13/e21/e32}{
        \draw(N\a)--(N\b) (N\b)--(N\c);
      }
      \foreach \a/\b/\c in {31/22/13,32/23/e11,33/e21/e12}{
        \draw[dashed](N\a)--(N\b) (N\b)--(N\c);
      }
    \end{tikzpicture}
    \caption{萨吕法则}
    \label{fig:Sarrus'-rule}
  \end{figure}
  
  则按实线三数乘积取正，虚线三数乘积取负，然后求和，可得$\det(M)$为
  \begin{align*}
    \det(M) ={}& +a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32}\\
               & -a_{31}a_{22}a_{13} + a_{32}a_{23}a_{11} - a_{33}a_{21}a_{12}
  \end{align*}
\end{example}


\section{向量}
\label{sec:vector}

通常$1\times n$的敌阵称为行向量，$n\times 1$的矩阵称为列向量，行向量与列向量都是向量，通常在上下文能确定是行向量还是列向量时，行列两字会省略。

\subsection{点积}
\label{sec:dot-product-of-vector}
\begin{definition}
  两个向量对应分量的积之和称为点积(dot product)，也称为数量积，通常记为$\vec a\cdot\vec b$或者$(\vec a,\vec b)$，或者$\langle\vec a,\vec b\rangle$，即
  \begin{align*}
    \vec{a}\cdot \vec b\equiv\sum_i a_ib_i
  \end{align*}
\end{definition}

显然，点积是满足交换律与分配律的，即
\begin{align*}
  \vec a\cdot \vec b={}&\vec b\cdot \vec a\\
  (\vec a + \vec b)\cdot \vec c ={}& \vec a\cdot \vec c + \vec b\cdot \vec c
\end{align*}
点积经过抽象又发展成了内积，由于点积与内积的相似性，内积空间理论中有很多与平面几何类似的结论。

\begin{example}[向量空间，线性空间，Vector Space，Linear Space]
  一条直线是一个一维的线性空间，一个平面是一个二维的线性空间，通常的三维欧氏空间是一个三维的线性空间。

  线性空间的定义涉及到线性组合。$n$个向量$\vec a_i$与$n$个实数系数$\alpha_i$的加权和，即
  \begin{align*}
    \sum_i \alpha_i \vec a_i
  \end{align*}
  上式称为向量组$\vec a_i$的一个线性组合。根据研究的需要，通常系数也可以从实数扩展到复数。

  线性空间通常是指由若干个向量$\{\vec a_i|i=1,2,\cdots,n\}$的所有线性组合而成的向量的集合，以及在这此集合中的向量上装配的向量操作(如线性组合)。单纯的线性空间一般不涉及拓扑结构。若在线性空间中再给向量赋予内积、距离等拓扑概念，线性空间就变成了巴拿赫(Banach)空间、希尔伯特(Hilbert)空间(也叫内积空间)、距离空间等。

  由$\{\vec a_i|i=1,2,\cdots,n\}$线性组合而得到的线性空间也称为由这些向量生成(张成)的空间，这些向量就是此空间的一组基。

  显然线性空间的基不是唯一的，因为往任意一组基里再额外添加一个该线性空间中的任意向量后仍然是该空间的一组基。因为基中向量的个数下限是0，因此存在一组基，其中的向量数量最少，此基的向量数量就是线性空间的维数。

  比如直线是一维的，因为其上任意一个非零向量可以张成该直线。平面是二维的，因为只要平面上两个不平行的向量就可以张成该平面。同样，立体空间是三维的。

  在没有配备点积\footnote{在内积空间中，点积又称为内积。}、距离等拓扑概念之前，线性空间是没有角度、垂直等概念的。当配备了拓扑结构后，若该空间的一组基中的向量两两垂直(也就是正交)，则称此基为正交基。
\end{example}

\begin{example}[线性相关，Linearly Dependent]
  $n$个向量是线性相关的，是指存在不全为零的实数$\alpha_i$，使得$\sum_i\alpha_i\vec a_i$为零向量。

  显然零向量与任意向量线性相关。三维欧氏空间中两向量线性相关等价于两者平行，三向量线性相关等价于三向量共面。$n$个不线性相关的非零向量可以张成一个$n$维空间。

  线性空间中两组非线性相关的、非零向量基，其向量个数相等。此问题的证明一般涉及到矩阵的秩和初等变换等知识，若看不明白，就请直接跳过。假设$\{\vec a_i|i=1,2,\cdots,n\}$和$\{\vec b_i|i=1,2,\cdots,m\}$是两组由非线性相关非零向量组成的基，且$n<m$，则对于前$n$个$\vec b_i$，存在实数矩阵使得
  \begin{align*}
    \begin{pmatrix}\vec b_1 \\ \vec b_2 \\ \vdots \\ \vec b_n\end{pmatrix}=
    \begin{pmatrix}
      \alpha_{11} & \alpha_{12} & \cdots & \alpha_{1n}\\
      \alpha_{21} & \alpha_{22} & \cdots & \alpha_{2n}\\
      \vdots      & \vdots      & \vdots & \vdots     \\
      \alpha_{n1} & \alpha_{n2} & \cdots & \alpha_{nn}
    \end{pmatrix}
    \begin{pmatrix}\vec a_1 \\ \vec a_2 \\ \vdots \\ \vec a_n\end{pmatrix}
  \end{align*}
  上式中的实系数矩阵必须是満秩的，也就是可逆的，否则{\color{red}怎样？某一行全变为零，又如何？矩阵变，b也在变}

  由系数矩阵的可逆性，存在其逆矩阵，使得
  \begin{align*}
    \begin{pmatrix}\vec a_1 \\ \vec a_2 \\ \vdots \\ \vec a_n\end{pmatrix}=
    \begin{pmatrix}
      \beta_{11} & \beta_{12} & \cdots & \beta_{1n}\\
      \beta_{21} & \beta_{22} & \cdots & \beta_{2n}\\
      \vdots     & \vdots     & \vdots & \vdots    \\
      \beta_{n1} & \beta_{n2} & \cdots & \beta_{nn}
    \end{pmatrix}
    \begin{pmatrix}\vec b_1 \\ \vec b_2 \\ \vdots \\ \vec b_n\end{pmatrix}
  \end{align*}
  即$\vec a_i$可由$\{\vec b_i|i=1,2,\cdots,n\}$生成，而对于$j>k$，$\vec b_j$可由$\vec a_i$线性组合而成，进而可由$\{\vec b_i|i=1,2,\cdots,n\}$组合而成，即存在实系数$\gamma_i$，使得
  \begin{align*}
    \vec b_j = \sum_{i=1}^n \gamma_i \vec b_i,\quad(j>n)
  \end{align*}
  这与非线性相关矛盾，从而必有$n=m$。
\end{example}

\begin{theorem}
  三维欧氏空间中任意两向量，有
  \begin{align*}
    \vec{a}\cdot \vec b=\left|\vec a\right| \cdot \left|\vec b\right| \cos\theta
  \end{align*}
  其中$\theta$是两向量之间的夹角，从而两向量之间夹角的余弦为
  \begin{align*}
    \cos\theta = \frac{\vec a\cdot \vec b}{\left|\vec a\right| \cdot \left|\vec b\right|}
  \end{align*}
\end{theorem}
\begin{proof}[提示]
  利用余弦定理。
  \begin{center}
    \begin{tikzpicture}[scale=1.0]
      \coordinate(O)at(0,0);
      \coordinate(A)at(3,0);
      \coordinate(B)at(2,2);
      \draw pic["$\theta$",<->,draw=orange,angle eccentricity=1.6,angle radius=.6cm]{angle=A--O--B};
      \draw[->](O)--(A)node[midway,below]{$\vec a$};
      \draw[->](O)--(B)node[midway,sloped,above]{$\vec b$};
      \draw[->](B)--(A)node[midway,sloped,above]{$\vec a - \vec b$};
    \end{tikzpicture}
  \end{center}
  由余弦定理，有
  \begin{align*}
    (\vec a-\vec b)\cdot(\vec a-\vec b) = \vec a\cdot \vec a + \vec b\cdot\vec b
    - 2\left|\vec a\right|\cdot\left|\vec b\right|\cos\theta
  \end{align*}
  展开可得。
\end{proof}

\begin{example}[点积就是投影]
  将上例中的式子改写成如下形式：
  \begin{align*}
    \vec a \cdot \frac{\vec b}{\left|\vec b\right|} = \left|\vec a\right|\cos\theta
  \end{align*}
  按此式及下图，可知$\vec a$与一个单位向量的点积为$\vec a$在此单位向量方向上投影长度，夹角为锐角时为正，钝角时为负，直角时为零。

  \centering
  \begin{tikzpicture}[scale=1.0]
    \coordinate(O)at(0,0);\coordinate(B)at(4,0);\coordinate(A)at(3,3);\coordinate(C)at(3,0);
    \draw[->](O)--(B)node[below]{$\vec b$};
    \draw[->](O)--(A)node[above]{$\vec a$};
    \draw[help lines](A)--(C);
    \draw(C)--(O)node[midway,below]{$\vec a\cdot\frac{\vec b}{\left|\vec b\right|}$};
    \draw pic["$\theta$",<->,draw=orange,angle eccentricity=1.6,angle radius=.6cm]{angle=B--O--A};
    \tkzDrawPoints(O,C);
  \end{tikzpicture}
\end{example}

\begin{example}[Gram-Schmidt正交化]
  点积(投影)在物理和工程上经常被用于分解向量，即将向量分解为两个或多个互相垂直的分量。常见的Gram-Schmidt正交化过程就用了点积(投影)的思想。

  %{\color{red}待补充。The geometry of the Gram-Schmidt orthogonalization process}

  通过$n$个非线性相关的向量$\vec a_i$，找到一组($n$个)互相正交(就是点积为零，互相垂直)的单位向量。其过程见图~\ref{fig:Gram-Schmidt-orthogonalization-process}
  \begin{enumerate}
  \item 随便找一个将其单位化(normalized)，记为$\vec b_1$，比如令
    \begin{align*}
      \vec b_1\equiv \frac{\vec a_1}{|\vec a_1|}
    \end{align*}

  \item 假设前$k$个$\vec a_i$已经单位正交化成了$\vec b_i$，通过$\vec a_{k+1}$找出第$k+1$个$\vec b_{k+1}$。将$\vec a_{k+1}$分解，扣除其在$\vec b_i(1\le i\le k)$上的分量，剩余的分量自然就与前$k$个$\vec b_i$垂直，即令
    \begin{align*}
      \vec a_{k+1}^\perp = \vec a_{k+1} - \sum_{i=1}^k (\vec a_{k+1}\cdot\vec b_i)\vec b_i
    \end{align*}
    则
    \begin{align*}
      (\vec a_{k+1}^\perp \cdot \vec b_i) = 0, \quad(1\le i\le k)
    \end{align*}
    从而令
    \begin{align*}
      \vec b_{k+1} = \frac{\vec a_{k+1}^\perp}{|\vec a_{k+1}^\perp|}
    \end{align*}
    则$\vec b_i\ (1\le i\le k+1)$是$k+1$个互相正交的单位向量。重复此步骤直到$n$个都处理完。
  \end{enumerate}

  \begin{figure}[htbp]
    \centering
    \begin{tikzpicture}[scale=1.0]
      \begin{scope}[shift={(0,0)}]
        \coordinate[label=below left:$O$](O)at(0,0);\coordinate(A)at(3,1);\coordinate(B)at(3,4);\coordinate(C)at(2,5);
        \coordinate(A')at($.5*(A)$);
        \coordinate(B')at($(O)!1!90:(A')$);
        \coordinate(PBB')at($(O)!(B)!(B')$);
        \coordinate(PBA')at($(O)!(B)!(A')$);
        \draw[dashed,help lines](A)--(PBA')--(B)--(PBB')--(B');
        \draw[->,line width=1.5pt](O)--(B')node[midway,left]{$\vec b_2$};
        \draw[->,line width=1.5pt](O)--(A')node[midway,below]{$\vec b_1$};
        \draw[->](A')--(A)node[below]{$\vec a_1$};
        \draw[->](O)--(B)node[above]{$\vec a_2$};
        \draw[->](O)--(C)node[above]{$\vec a_3$};
        \tkzMarkRightAngle[help lines,dashed](O,PBA',B)
        \tkzMarkRightAngle[help lines,dashed](O,PBB',B)
      \end{scope}
      \begin{scope}[shift={(6,0)}]
        \coordinate[label=below left:$O$](O)at(0,0);\coordinate(A)at(3,1);\coordinate(B)at(3,4);\coordinate(C)at(2,5);
        \coordinate(A')at($.5*(A)$);
        \coordinate(B')at($(O)!1!90:(A')$);
        \coordinate(PBB')at($(O)!(B)!(B')$);
        \coordinate(PBA')at($(O)!(B)!(A')$);
        \coordinate(P)at(2,3);
        \coordinate(CA)at($(O)!(P)!(A')$);
        \coordinate(CB)at($(O)!(P)!(B')$);
        \coordinate(CZ)at($(C)+(O)-(P)$);
        \coordinate(C')at($.8*(CZ)$);
        \draw[dashed,help lines](A)--(PBA')--(B)--(PBB')--(B')
        (CA)--(C)--(CB)
        (C')--(CZ)--(C)--(P)--(CA) (O)--(P)--(CB);
        \draw[->,line width=1.5pt](O)--(C')node[right]{$\vec b_3$};
        \draw[->,line width=1.5pt](O)--(B')node[midway,left]{$\vec b_2$};
        \draw[->,line width=1.5pt](O)--(A')node[midway,below]{$\vec b_1$};
        \draw[->](A')--(A)node[below]{$\vec a_1$};
        \draw[->](O)--(B)node[above]{$\vec a_2$};
        \draw[->](O)--(C)node[above]{$\vec a_3$};
        \tkzMarkRightAngle[help lines,dashed](O,PBA',B)
        \tkzMarkRightAngle[help lines,dashed](O,PBB',B)
        \tkzMarkRightAngle[help lines,dashed](O,P,C)
        \tkzMarkRightAngle[help lines,dashed](O,CA,P)
        \tkzMarkRightAngle[help lines,dashed](O,CB,P)
      \end{scope}
    \end{tikzpicture}

    \caption{Gram-Schmidt正交化过程}
    \label{fig:Gram-Schmidt-orthogonalization-process}
  \end{figure}
\end{example}

\begin{example}[平面向量的旋转]
  记$\vec a$是平面上二维向量，其在直角坐标系下的两分量为$a_x$与$a_y$，即
  \begin{align*}
    \vec a\equiv
    \begin{pmatrix}
      a_x\\ a_y
    \end{pmatrix}
  \end{align*}
  现将向量沿坐标原点逆时针旋转$\theta$度，记旋转后得到的向量为$\vec a'$。若分别用复数$z$与$z'$表示向量$\vec a$和$\vec a'$，则有
  \begin{align*}
    z' ={}& z\cdot e^{i\theta} = (\cos\theta + i\sin\theta)\cdot (a_x + i a_y)\\
       ={}& a_x \cos\theta - a_y \sin\theta + i(a_x \sin\theta + a_y \cos\theta)\\
       ={}& (\cos\theta,\ -\sin\theta)\begin{pmatrix}a_x\\a_y\end{pmatrix} + i
            (\sin\theta,\  \cos\theta)\begin{pmatrix}a_x\\a_y\end{pmatrix}
  \end{align*}
  写成矩阵的形式，就有
  \begin{align*}
    \begin{pmatrix}
      a_x'\\ a_y'
    \end{pmatrix}=
    \begin{pmatrix}
      \cos\theta & -\sin\theta\\
      \sin\theta & \phantom{-}\cos\theta
    \end{pmatrix}
    \begin{pmatrix}
      a_x\\ a_y
    \end{pmatrix}
  \end{align*}
  上式中的矩阵称为旋转矩阵(Rotate Matrix)。
\end{example}

\begin{example}[垂直向量]
  逆时针旋转$90^\circ$，即旋转矩阵中$\theta$取为$\pi/2$。记旋转后的向量为$\vec a^\perp$，则有
  \begin{align*}
    \vec a^\perp = 
    \begin{pmatrix}
      a_x^\perp\\ a_y^\perp
    \end{pmatrix}=
    \begin{pmatrix}
      0 & -1\\
      1 & \phantom{-}0
    \end{pmatrix}
    \begin{pmatrix}
      a_x\\ a_y
    \end{pmatrix}=
    \begin{pmatrix}
      -a_y\\ a_x
    \end{pmatrix}
  \end{align*}
  若是顺时针旋转$90^\circ$，则可以得到另一个垂直向量$(a_y,\ -a_x)^T$，其中$^T$表示转置。
\end{example}

\begin{definition}[Perp Dot Product]
  平面欧氏空间中的向量$\vec a$逆时针旋转$90^\circ$后得到的向量与向量$\vec b$的点积，称为向量$\vec a$与$\vec b$的Perp Dot Product，即
  \begin{align*}
    \vec a^\perp \cdot \vec b =
    \begin{pmatrix}
      -a_y\\ a_x
    \end{pmatrix} \cdot
    \begin{pmatrix}
      b_x\\ b_y
    \end{pmatrix} =
    \begin{pmatrix}
      -a_y & a_x
    \end{pmatrix}
    \begin{pmatrix}
      b_x\\ b_y
    \end{pmatrix} =
    a_xb_y - a_yb_x
  \end{align*}
\end{definition}

\begin{theorem}
  平面欧氏空间中任意两向量$\vec a$和$\vec b$，有
  \begin{align*}
    \vec a^\perp\cdot \vec b={}&\pm \left|\vec a\right|\cdot\left|\vec b\right|\sin\theta\\
    \left(\vec a^\perp\cdot \vec b\right)^2 + \left(\vec a\cdot\vec b\right)^2 ={}& \left|\vec a\right|^2 \cdot \left|\vec b\right|^2
  \end{align*}
\end{theorem}
\begin{proof}[提示]
  由$\vec a^\perp$与$\vec b$的夹角为$\pi/2 \pm \theta$，且
  \begin{align*}
    \cos\left(\frac\pi2\pm\theta\right)=\mp\sin\theta
  \end{align*}
  可得。
\end{proof}


\subsection{叉积}
\label{sec:cross-product-of-vector}
\begin{definition}[叉积，外积，法向量，Cross Product]
  三维欧氏空间中的向量的叉积按下式定义：
  \begin{align*}
    \vec{a}\times\vec{b}\equiv
    \begin{vmatrix}
      \ihat  & \jhat  & \khat\\
      a_1    & a_2    & a_3\\
      b_1    & b_2    & b_3
    \end{vmatrix}
  \end{align*}
  其中$\ihat, \jhat, \khat$是三维欧氏空间中正交坐标下的三个单位正交向量。
\end{definition}
其中的$\vec i$，$\vec j$和$\vec k$是三维欧氏空间中的一个满足右手法则的单位正交基\footnote{\color{red}需要介绍一下右手法则和正交基吗？}。显然，叉积是满足负交换律和分配律的，即
\begin{align*}
  \vec a\times \vec b ={}& - \vec b\times \vec a\\
  (\vec a + \vec b)\times \vec c ={}& \vec a\times \vec c + \vec b\times \vec c
\end{align*}

\begin{example}
  在叉积的定义中，分别令$\vec a$和$\vec b$为$\vec i$，$\vec j$和$\vec k$，容易知道
  \begin{gather*}
    \vec i \times \vec i = \vec j\times \vec j=\vec k\times \vec k = 0\\
    \vec i\times \vec j = \vec k,\quad \vec j\times \vec k = \vec i,\quad \vec k\times \vec i = \vec j
  \end{gather*}

  同样，对于点积，有
  \begin{gather*}\setlength\arraycolsep{2pt}\renewcommand*{\arraystretch}{1.0}
    \begin{array}{cccccccccccc}
      \vec i & \cdot & \vec i & = & \vec j & \cdot & \vec j & = & \vec k & \cdot & \vec k & = 1\\
      \vec i & \cdot & \vec j & = & \vec j & \cdot & \vec k & = & \vec k & \cdot & \vec i & = 0
    \end{array}
  \end{gather*}
\end{example}

\begin{theorem}若$\vec a$，$\vec b$，$\vec c$是$\vec i$，$\vec j$和$\vec k$的任一排列，则有
  \begin{align*}
    (\vec a\times \vec b)\cdot \vec c = \pm 1
  \end{align*}
  正负号取决于$\vec a$，$\vec b$，$\vec c$是满足右手法则还是左手法则。特别的，有
  \begin{align*}
    (\vec i\times \vec j)\cdot \vec k =
    (\vec j\times \vec k)\cdot \vec i =
    (\vec k\times \vec i)\cdot \vec j = 1
  \end{align*}
\end{theorem}

\begin{theorem}三维欧氏空间中任意两非零向量$\vec a$和$\vec b$，有
  % \begin{align*}\setlength\arraycolsep{2pt}\renewcommand*{\arraystretch}{1.0}
  %   \begin{array}{cccccc}
  %     \vec a & \perp     &\vec b &\quad \iff\quad \vec a & \cdot  &\vec b = 0\\
  %     \vec a & \parallel &\vec b &\quad \iff\quad \vec a & \times &\vec b = 0
  %   \end{array}
  % \end{align*}
  \begin{align*}
    \vec a \perp     \vec b \iff \vec a \cdot  \vec b = 0,\quad\quad
    \vec a \parallel \vec b \iff \vec a \times \vec b = 0
  \end{align*}
\end{theorem}


\begin{definition}[混合积，标量三重积，Scalar Triple Product，Box Product]
  $\forall \vec a,\vec b,\vec c\in\mathbb{R}^3$，称
  \begin{align*}
    \vec a\cdot(\vec b\times\vec c)
  \end{align*}
  为三者的混合积。
\end{definition}

\begin{theorem}
  $\forall \vec a,\vec b,\vec c\in\mathbb{R}^3$，其混合积可由行列式给出：
  \begin{align*}\renewcommand{\arraystretch}{.9}
    \vec a\cdot(\vec b\times\vec c) =
    \begin{vmatrix}
      a_1 & a_2 & a_3\\
      b_1 & b_2 & b_3\\
      c_1 & c_2 & c_3
    \end{vmatrix}
  \end{align*}
\end{theorem}
\begin{proof}[提示]
  直观的方法是将叉积的行列式表达方式代入，比较两边可得。纯计算，无需技巧。
  \begin{align*}\renewcommand{\arraystretch}{.9}
    \vec a\cdot (\vec b\times \vec c) ={}& (a_1\vec i + a_2\vec j + a_3\vec k) \cdot
    \begin{vmatrix}
      \vec i & \vec j & \vec k\\
      b_1 & b_2 & b_3\\
      c_1 & c_2 & c_3
    \end{vmatrix}\\
    ={}& a_1 \begin{vmatrix} b_2 & b_3\\ c_2 & c_3  \end{vmatrix}
       - a_2 \begin{vmatrix} b_1 & b_3\\ c_1 & c_3  \end{vmatrix}
       + a_3 \begin{vmatrix} b_1 & b_2\\ c_1 & c_2  \end{vmatrix}
      =
      \begin{vmatrix}
        a_1 & a_2 & a_3\\
        b_1 & b_2 & b_3\\
        c_1 & c_2 & c_3
      \end{vmatrix}
  \end{align*}

  由此可知，$\forall \vec a, \vec b\in\mathbb{R}^3$，有
  \begin{align*}
    \vec a\cdot (\vec a\times \vec b) = \vec b\cdot(\vec a\times \vec b) = 0
  \end{align*}
  即叉积与原两向量均垂直。
\end{proof}

\begin{example}[混合积的shift property]由行列式的性质，顺序置换三个向量的位置其混合积不变，即
  \def\scalarTripleProd[#1,#2,#3]{
    \vec {#1}\cdot(\vec {#2}\times\vec #3)
  }
  \begin{align*}
    \scalarTripleProd[a,b,c] =
    \scalarTripleProd[b,c,a] =
    \scalarTripleProd[c,a,b]
  \end{align*}

  \think 若对换两个向量的位置呢？
\end{example}

\begin{example}[混合积的几何意义]
  混合积还有个叫Box Product的名字，这是因为混合积的绝对值是3个向量为邻边组成的平行六面体的体积，当3向量满足右手法则时结果为正，满足左手法则时为负。

  记$\vec b\times \vec c$的单位向量为$\vec w$，则$\vec a$在$\vec w$上的投影即六面体的高$h$为
  \begin{align*}
    h = |\vec a \cdot \vec w| =
    \left|\vec a\cdot \frac{\vec b\times \vec c}{|\vec b\times\vec c|} \right|
  \end{align*}
  而六面体的底面积为
  \begin{align*}
    S = |\vec b\times\vec c|
  \end{align*}
  两者相乘可得六面体的体积$V$为
  \begin{align*}
    V=Sh =|\vec a\cdot(\vec b\times \vec c)| &\qedhere
  \end{align*}
  \color{red}补一个示意图。
\end{example}

\begin{question}
  关于$\mathcal{R}^3$ 中始点在原点的三向量%$\vec a, \vec b,\vec c$
  ，以下说法互相等价：
  \begin{enumerate}
  \item 三向量共面。
  \item 三向量的混合积为零。
  \item 三向量组成的矩阵非满秩。\color{red}要补充下矩阵的秩。
  \end{enumerate}
\end{question}

\begin{definition}[右手系]
  $\mathbb{R}^3$中三个正交向量$\vec u$，$\vec v$和$\vec w$若满足
  \begin{align*}
    \vec u \cdot (\vec v\times \vec w) > 0
  \end{align*}
  则称此三个正交向量为右手系。反之，若$<0$，则称为左手系。
\end{definition}

\begin{lemma}
  $\mathbb{R}^3$中两个非零不平行的向量$\vec a$，$\vec b$，则$(\vec a\times \vec b, \vec a, \vec b)$是右手系统。
\end{lemma}
\begin{proof}
  由$\vec a\not\parallel\vec b$，有$\vec a \times \vec b$为非零向量。由右手系统的定义，有
  \begin{align*}
    (\vec a\times \vec b) \cdot (\vec a\times \vec b) = \left| \vec a\times \vec b \right|^2 > 0
  \end{align*}
  从而$(\vec a\times \vec b, \vec a, \vec b)$是右手系统。
\end{proof}

\begin{lemma}\label{lem:c-prod2+dot-prod2=a2+b2}
  $\forall \vec a, \vec b\in\mathbb{R}^3$，有
  \begin{align*}
    \left|\vec a\times \vec b\right|^2 + (\vec a\cdot \vec b)^2 =
    \left|\vec a\right|^2 + \left|\vec b\right|^2
  \end{align*}
\end{lemma}
\begin{proof}[提示]
  直观但繁琐的方法，是直接展开两边对比可得。
\end{proof}

\begin{example}
  由引理~\ref{lem:c-prod2+dot-prod2=a2+b2}，可得$n=3$时的C--S不等式{\color{red}or Minkowski不等式？需要确认}。由
  \begin{align*}
    \left|\vec a\times \vec b\right|^2 = 
    \left|\vec a\right|^2 + \left|\vec b\right|^2
    - (\vec a\cdot \vec b)^2
  \end{align*}
  可知C--S不等式{\color{red}or Minkowski不等式？需要确认}中两边相差一个外积的模的平方，当且仅当月外积为零即两向量平行时等号成立。
\end{example}

\begin{question}
  除了3维欧氏空间中可以定义外积，7维欧氏空间也可以定义外积。当$n=7$时是否也有相应的恒等式？
\end{question}


\begin{theorem}
  记$\vec p\equiv\vec a\times \vec b$，则$\vec a$，$\vec b$和$\vec p$满足右手法则，且$\vec p$同时垂直于$\vec a$和$\vec b$，且外积$\vec p$的模为$\left|\vec a\right|\cdot\left|\vec b\right|\sin\theta$，其中$\theta$是$\vec a$与$\vec b$的夹角。即
  \begin{gather*}
    (\vec a\times \vec b)\cdot \vec a = (\vec a\times \vec b)\cdot \vec b = 0\\
    \left| \vec a\times \vec b\right| = \left| \vec a\right| \cdot \left| \vec b\right| \sin\theta
  \end{gather*}
\end{theorem}
% \begin{proof}[提示]
%   直接代入，有
%   \begin{align*}
%     (\vec a\times \vec b)\cdot \vec a ={}&
%     \begin{vmatrix}
%       \vec i & \vec j & \vec k\\
%       a_1    & a_2    & a_3\\
%       b_1    & b_2    & b_3
%     \end{vmatrix}\cdot (a_1\vec i + a_2\vec j + a_3\vec k)\\
%     ={}& \left[(a_2b_3 - a_3b_2)\vec i + (a_3b_1 - a_1b_3)\vec j + (a_1b_2 - a_2b_1)\vec k\right] \\
%        & \cdot (a_1\vec i + a_2\vec j + a_3\vec k)\\
%     ={}& a_1(\underline{a_2b_3} - \cancel{a_3b_2}) + a_2(a_3b_1 - \underline{a_1b_3}) + a_3(\cancel{a_1b_2} - a_2b_1) = 0
%   \end{align*}
%   同理有$(\vec a\times \vec b)\cdot \vec b = 0$。
% \end{proof}
\begin{proof}
  综合上面各个引理的，并由$\vec a\cdot\vec b=\left|\vec a\right|\cdot\left|\vec b\right|\cos\theta$可得。
\end{proof}

由此定理可知，$\left|\vec a\times \vec b\right|$是由两向量为邻边组成的平行四边形的面积，或等价地，是两向量组成的三角形的面积的2倍，如下图所示。
\begin{center}
  \begin{tikzpicture}[scale=1.0]
    \coordinate(O)at(0,0);
    \coordinate(A)at(4,0);
    \coordinate(B)at(1.5,2);
    \coordinate(C)at($(A)+(B)-(O)$);
    \fill[color=blue!10](O)--(A)--(B)--cycle;
    \draw[dashed,help lines](A)--(C)--(B)--($(O)!(B)!(A)$)node[midway,right,black]{$\left|\vec b\right|\sin\theta$};
    \draw[->](O)--(A)node[pos=.8,below]{$\vec a$};
    \draw[->](O)--(B)node[pos=.8,sloped,above]{$\vec b$};
    \draw pic["$\theta$",<->,draw=orange,angle eccentricity=1.6,angle radius=.6cm]{angle=A--O--B};
  \end{tikzpicture}
\end{center}

\subsection{三角形面积}
\label{sec:area-of-triangle-by-vector}

\begin{lemma}
  平面上两起点为原点的向量$\vec a$和$\vec b$，其终点与原点组成的三角形的面积$S_{\triangle AOB}$为
  \begin{align*}
    S_{\triangle AOB} = \frac12\left| \det(M) \right|
  \end{align*}
  其中
  \begin{align*}\renewcommand{\arraystretch}{.9}
    M\equiv\begin{pmatrix}a_x & a_y\\ b_x & b_y\end{pmatrix}
  \end{align*}

  \centering
  \begin{tikzpicture}[scale=1.0]
    \coordinate[label=below left:$O$](O)at(0,0);
    \coordinate[label=right:$A$](A)at(3,1);
    \coordinate[label=above:$B$](B)at(1,2);
    \fill[color=blue!10](O)--(A)--(B)--cycle;
    \draw[->](-1,0)--(4,0);
    \draw[->](0,-1)--(0,3);
    \draw[->](O)--(A);
    \draw[->](O)--(B);
    \draw pic["$\theta$",<->,draw=orange,angle eccentricity=1.6,angle radius=.6cm]{angle=A--O--B};
  \end{tikzpicture}
\end{lemma}
\begin{proof}[提示]利用正弦形式的三角形面积公式
  \begin{align*}
    S=\frac12 ab\sin\theta\implies
    S_{\triangle AOB} = \frac12 |\vec a| \cdot |\vec b| \cdot \sin\theta
  \end{align*}
  由叉积的定义及性质，有
  \begin{align*}\renewcommand{\arraystretch}{.9}
    \vec a\times \vec b = 
    \begin{pmatrix}
      \ihat & \jhat & \khat\\
      a_x   & a_y   & 0\\
      b_x   & b_y   & 0
    \end{pmatrix} =
    \begin{vmatrix}
      a_x   & a_y\\
      b_x   & b_y
    \end{vmatrix}\khat
  \end{align*}
  由
  \begin{align*}
    \left|\vec a\times \vec b\right| = |\vec a|\cdot|\vec b|\cdot\sin\theta
  \end{align*}
  代入，有
  \begin{align*}
    S_{\triangle AOB} = \frac12 |\det(M)|&\qedhere
  \end{align*}
\end{proof}

\begin{theorem}[三角形面积的行列式公式]
  记平面直角坐标系下三角形的3个顶点的坐标分别为$(x_1, y_1)$，$(x_2,y_2)$和$(x_3,y_3)$，则三角形的面积为
  \begin{align*}
    S =\frac12 \left| \det(M) \right|
  \end{align*}
  其中
  \begin{align*}\renewcommand{\arraystretch}{.9}
    M\equiv
    \begin{pmatrix}
      x_1 & y_1 & 1\\
      x_2 & y_2 & 1\\
      x_3 & y_3 & 1
    \end{pmatrix}
  \end{align*}
\end{theorem}
\begin{proof}[提示]
  利用上面的引理，将坐标原点移到某个顶点上，比如$(x_1,y_1)$，则三角形三顶点的坐标在新坐标系下变为
  \begin{align*}
    (0,0),\quad (x_2-x_1, y_2-y_1),\quad (x_3-x_1, y_3-y_1)
  \end{align*}
  从而且面积为
  \begin{align*}
    S = \frac12 |\det(M)|
  \end{align*}
  其中
  \begin{align*}\renewcommand{\arraystretch}{.9}
    \det(M) =
    \begin{vmatrix}
      x_2 - x_1 & y_2 - y_1\\
      x_3 - x_1 & y_3 - y_1
    \end{vmatrix} =
    \begin{vmatrix}
      1 & 0         & 0        \\     
      1 & x_2 - x_1 & y_2 - y_1\\
      1 & x_3 - x_1 & y_3 - y_1
    \end{vmatrix} =
    \begin{vmatrix}
      1 & x_1 & y_1\\     
      1 & x_2 & y_2\\
      1 & x_3 & y_3
    \end{vmatrix}
  \end{align*}
  主要是两点，一个是坐标平移，一个行列式变换(第2列加上第1列的$x_1$倍，第3列加上第1列的$y_1$倍)。
\end{proof}


\subsection{BAC--CAB法则}
\label{sec:BAC-CAB-rule}

\begin{definition}[向量三重积，Vector Triple Product]
  $\forall \vec a,\vec b,\vec c\in\mathbb{R}^3$，称
  \begin{align*}
    \vec a\times(\vec b\times \vec c)
  \end{align*}
  为三者的向量三重积。
\end{definition}

\begin{lemma}[bac--cab Rule\footnote{有个简便的记忆方法：发音为BACK--CAB，意为“后面的出租车”。}]
  $\forall \vec a,\vec b,\vec c\in\mathbb{R}^3$，有
  \begin{align*}
    \vec a\times(\vec b\times \vec c)=\vec b(\vec a,\vec c) - \vec c(\vec a,\vec b)
  \end{align*}
\end{lemma}
\begin{proof}
  最直观的证明是直接展开，对比三个分量。这里不再加以描述。

  另一种方法，是待定系数法。不妨设$\vec b\not\parallel\vec c$，否则显然两边都为零向量。由
  \begin{align*}
    \vec b\times\vec c\perp \vec b,\quad \vec b\times\vec c\perp \vec c,\quad
    \vec a\times(\vec b\times\vec c)\perp \vec b\times \vec c
  \end{align*}
  可知$\vec a\times(\vec b\times\vec c)$必在$\vec b$和$\vec c$张成的空间(在这里是一个平面)里\footnote{因为垂直于向量$\vec b\times\vec c$的平面就是$\vec b$和$\vec c$张成的平面。\color{red}补充一下张成空间的概念？}，从而$\exists s,t\in\mathbb{R}$，使得
  \begin{align*}
    \vec a\times(\vec b\times\vec c) = s\vec b +t\vec c
  \end{align*}
  两边与$\vec a$作点积，则有
  \begin{align*}
    s(\vec a,\vec b)+t(\vec a,\vec c)=(\vec a, \vec a\times(\vec b\times\vec c))=0
  \end{align*}
  显然
  \begin{align*}
    s=(\vec a,\vec c),\quad
    t=-(\vec a,\vec b)
  \end{align*}
  是上式的其中一组解。{\color{red}但不一定是原待定系数方程的解。需要换一个思路。}对上述的$s,t$，考虑向量$\vec u$
  \begin{align*}
    \vec u\equiv \vec b(\vec a,\vec c) - \vec c(\vec a, \vec b)
  \end{align*}
  容易验证$\vec u\cdot \vec a=0$，从而$\vec u\perp\vec a$，且$\vec u\perp\vec (\vec b\times\vec c)$，从而存在$\lambda\in\mathbb{R}$，使得
  \begin{align*}
    \lambda \vec u = \vec a\times(\vec b\times\vec c)
  \end{align*}
  即
  \begin{align*}
    \lambda(\vec b(\vec a,\vec c) - \vec c(\vec a, \vec b)) = \vec a\times(\vec b\times\vec c)
  \end{align*}
  {\color{red}若$\lambda$是与$\vec a,\vec b,\vec c$无关的常数，则直接将$\ihat, \jhat, \khat$代入可得$\lambda=1$。}


  % Here's an alternate proof, assuming you know that AxB is always
  % orthogonal to both A and B, and a few more facts. It may or may not be
  % helpful.

  % We know [imath]A \times (B \times C)[/imath] is orthogonal to [imath]B
  % \times C[/imath], which is orthogonal to the plane containing
  % [imath]B[/imath] and [imath]C[/imath], so [imath]A \times (B \times
  % C)[/imath] is in the plane spanned by [imath]B[/imath] and
  % [imath]C[/imath] and is orthogonal to [imath]A[/imath]. Furthermore,
  % if you take the dot product of [imath]A[/imath] with [imath]B(A\cdot
  % C)-C(A\cdot B)[/imath] you get [math](A\cdot B)(A\cdot C)-(A \cdot
  % C)(A\cdot B)=0,[/math] so [imath]B(A\cdot C)-C(A\cdot B)[/imath] is in
  % the plane spanned by [imath]B[/imath] and [imath]C[/imath], and is
  % orthogonal to [imath]A[/imath]. Thus we have [math]A\times (B\times
  % C)=\lambda[B (A\cdot C)-C (A\cdot B)][/math] for some scalar
  % [imath]\lambda[/imath]. Since the scalar and dot products are both
  % bilinear, both sides of the original expression are trilinear in
  % [imath]A[/imath], [imath]B[/imath], and [imath]C[/imath], so the
  % factor [imath]\lambda[/imath] cannot depend on [imath]A[/imath],
  % [imath]B[/imath], or [imath]C[/imath]. Plugging in i, i, and j in for
  % [imath]A, B, C[/imath] tells us that [imath]\lambda[/imath] is 1.

  % It's certainly a more complicated proof than just doing the algebra,
  % but it may give you a bit better sense of why the identity is true. At
  % the very least you should understand why [imath]A \times (B \times
  % C)[/imath] should be equal to something times B plus something times
  % C, and why (and perhaps a rough idea of how) those somethings should
  % depend on A.

  下面是另外一种方法。考虑满足右手法则的单位正交基
  \begin{align*}
    \ihat \equiv \frac{\vec b}{\left|\vec b\right|},\quad
    \jhat \equiv \frac{\vec b^\perp}{\left|\vec b^\perp\right|},\quad
    \khat \equiv \frac{\vec b\times \vec c}{\left|\vec b\times\vec c\right|}
  \end{align*}
  其中$\vec b^\perp$是$\vec b$和$\vec c$张成的平面内$\vec b$向$\vec c$方向旋转$90^\circ$而成的向量。对$\vec a,\vec b,\vec c$按此正交基作正交分解，记分解结果为
  \begin{align*}\renewcommand{\arraystretch}{.9}
    \vec a=(a_1, a_2, a_3)\begin{pmatrix}\ihat\\ \jhat\\ \khat\end{pmatrix}, \quad
    \vec b=(b_1,   0,   0)\begin{pmatrix}\ihat\\ \jhat\\ \khat\end{pmatrix}, \quad
    \vec c=(c_1, c_2,   0)\begin{pmatrix}\ihat\\ \jhat\\ \khat\end{pmatrix}
  \end{align*}
  其中有不少的零，计算可大大简化。代入左边，有
  \begin{align*}
    \vec a\times(\vec b\times\vec c) ={}& (a_1\ihat + a_2\jhat)\times(b_1\ihat \times c_2\jhat)\\
    ={}& (a_1\ihat + a_2\jhat)\times(bc_2\khat) = a_2bc_2\ihat - a_1bc_2\jhat
  \end{align*}
  同样的，考虑右手边则有
  \begin{align*}
    \vec b(\vec a,\vec c) - \vec c(\vec a,\vec b) = (\underline{a_1c_1} + a_2c_2) b_1\ihat  - (a_1b_1)(\underline{c_1\ihat} + c_2\jhat)
    =a_2b_1c_2\ihat - a_1b_1c_2\jhat
  \end{align*}
  从而左右相等。\footnote{这里应用到了点积、叉积是坐标系变换下的不变量，需要补充一下。}
  % 将$\vec c$作按$\vec b$和$\vec b^\perp$两个方向作正交分解，记为
  % \begin{align*}
  %   \vec c={\vec c}_b + {\vec c}_\perp
  % \end{align*}
  % 其中$\vec c_b \parallel \vec b$，$\vec c_\perp \perp \vec b$。同样对$\vec a$作按$\vec b\times \vec c$方向，与$\vec b$和$\vec c$张成的平面这两个方向作正交分解，记其在$\vec b$和$\vec c$张成的平面内的分量为$\vec a_{bc}$，则  
  % \begin{align*}
  %   \vec a\times(\vec b\times \vec c) = \vec a_{bc}\times(\vec b\times \vec c_\perp) \\
  %   s
  % \end{align*}
\end{proof}

\begin{example}[拉格朗日恒等式，Lagrange's Identity]
  $\forall \vec a,\vec b,\vec c,\vec d\in\mathbb{R}^3$，有
  \begin{align*}
    (\vec a\times \vec b) \cdot (\vec c\times \vec d) =
    (\vec a\cdot \vec c)(\vec b\cdot \vec d) - (\vec a\cdot \vec d)(\vec b\cdot \vec c)
  \end{align*}
  % \verb+  A quick googling for "proof Lagrange vector triple product" returned a number of articles. Someone named Robert C. Wrede apparently gave a proof which utilized tensor notation, but the one I actually bothered to login to JSTOR for (by Daniel T. Dwyer) proves a related identity instead: [math](A\times B)\cdot (C\times D)=(A\cdot C)(B\cdot D)-(A\cdot D)(B\cdot C)[/math] The article says that the BAC CAB identity follows directly from this, though I'm not seeing it at the moment... Anyway, for the proof of that identity he uses the determinant representations of the triple scalar product to show that [math](A\times B)\cdot (C\times D)=A\cdot (B\times (C\times D))=((A\times B)\times C)\cdot D[/math] Then he again uses the determinant representation, along with the rule for multiplying determinants, to obtain [math][(A\times B)\cdot (C\times D)]^2=[(C\times D)\cdot (A\times B)][(A\cdot C)(B\cdot D)-(A\cdot D)(B\cdot C)][/math] The article's identity follows pretty easily from there... \verb+
  利用混合积的性质，将$\vec a\times\vec b$看作一个整体。
  \begin{align*}
    (\vec a\times \vec b) \cdot (\vec c\times \vec d) ={}&
    \vec c \cdot (\vec d\times (\vec a\times \vec b)) &&\text{混合积的shift property}\\
    ={}& \vec c\cdot( \vec a(\vec d\cdot\vec b) -\vec b(\vec d\cdot\vec a) ) && \text{BAC--CAB rule}\\
    ={}& (\vec c\cdot\vec a)(\vec d\cdot\vec b) - (\vec c\cdot\vec b)(\vec d\cdot\vec a) &&\text{分配律}\\
    ={}& (\vec a\cdot\vec c)(\vec b\cdot\vec d) - (\vec b\cdot\vec c)(\vec a\cdot\vec d) &&\text{交换律}
  \end{align*}
\end{example}

\subsection{平面几何上的应用}
\label{sec:application-on-geometry-of-vector}

\begin{example}[垂足坐标]
  $\mathbb{R}^3$不共线的三点$a$，$b$和$c$，求点$c$到过点$a$和$b$的直线的垂足的坐标。
\end{example}
\begin{proof}[提示]
  记各点对应在的向量为$\vec a$，$\vec b$和$\vec c$。则过点$a$和$b$的直线上的任一点$u$对应的向量$\vec u$都可以写为
  \begin{align*}
    \vec u=\vec a + s\cdot(\vec b-\vec a)
  \end{align*}
  其中$s\in\mathbb{R}$，表示该点与$a$的有向距离与$a$、$b$两点间距离的比值，与点$b$同侧为正，异侧为负。由此，要确定$c$在$\overline{ab}$上的投影的坐标，只要确定其投影的长度即可。由点积，可知其投影长度$L_{proj,c}$为
  \begin{alignat*}{3}
    &&L_{proj,c} ={}& (\vec c-\vec a)\cdot \frac{\vec b - \vec a}{\left| \vec b - \vec a \right|}\\
    \implies&& s ={}& \frac{L_{proj,c}}{\left| \vec b - \vec a \right|} =
    \frac{(\vec c-\vec a)\cdot(\vec b - \vec a)}{\left| \vec b - \vec a \right|^2}
  \end{alignat*}
  若记$\vec w$为$\vec b-\vec a$方向的单位向量，即
  \begin{align*}
    \vec w\equiv \frac{\vec b - \vec a}{\left| \vec b - \vec a \right|}
  \end{align*}
  则$c$在$\overline{ab}$上的投影点$u_{proj,c}$对应的向量$\vec u_{proj,c}$可按下式计算得到：
  \begin{align*}
    L_{proj,c} ={}& (\vec c-\vec a)\cdot \vec w, \quad
             s ={} \frac{L_{proj,c}}{\left| \vec b - \vec a \right|}\\
    \vec u_{proj,c}={}& \vec a + \frac{((\vec c-\vec a)\cdot\vec w)(\vec b-\vec a)}{\left| \vec b - \vec a \right|}
                        =\vec a + ((\vec c-\vec a)\cdot\vec w)\vec w
  \end{align*}
  这是从线的方程出发，步骤较多，事实上若由下图出发，则可直接得到结论。
  \begin{center}
    \begin{tikzpicture}[scale=1.0]
      % \coordinate(O)at(-2,-3);
      \coordinate[label=below left:$a$](A)at(0,0);
      \coordinate[label=right:$b$](B)at(4,0);
      \coordinate[label=above:$c$](C)at(3,2);
      \coordinate[label=below:$u$](U)at($(A)!(C)!(B)$);
      % \draw[help lines,->](O)--(A)node[midway,black]{$\vec a$};
      % \draw[help lines,->](O)--(B)node[midway,black]{$\vec b$};
      % \draw[help lines,->](O)--(C)node[midway,black]{$\vec c$};
      \draw[->](A)--(C)node[midway,sloped,above]{$\vec c - \vec a$};
      \draw[->](U)--(B);%node[midway,below,pos=1]{$\vec b - \vec a$};
      \draw(A)--(U)node[midway,above]{$\vec w$} node[midway,below]{$(\vec c-\vec a)\cdot \vec w$};
      \draw[dashed,help lines](C)--(U);
      \tkzDrawPoints(A,U);
    \end{tikzpicture}
  \end{center}
  图中点$u$为$c$在$\overline{ab}$上的投影点，则\overrightharp{$\vec{au}$}的长度为
  \begin{align*}
    \left|\text{\overrightharp{$\vec{au}$}}\right| = (\vec c - \vec a)\cdot \vec w \implies
    \text{\overrightharp{$\vec{au}$}} = ((\vec c - \vec a)\cdot \vec w) \vec w
  \end{align*}
  从而
  \begin{align*}
    \vec u = \vec a + \text{\overrightharp{$\vec{au}$}} = \vec a + ((\vec c -\vec a)\cdot \vec w) \vec w
  \end{align*}
  此公式除了在计算\overrightharp{$\vec{ab}$}的单位向量$\vec w$时有一次开方运算外，其余都是加减乘除四则运算。
\end{proof}


\begin{example}[反射点，对称点]
  $\forall a, b, c\in\mathbb{R}^3$，求点$c$关于直线$\overline{ab}$的对称点$d$。
\end{example}
\begin{proof}[提示]
  先求垂足$u$，再由$c,d$关于$u$对称可得。
  \begin{align*}
    \vec u ={}& \vec a + ((\vec c -\vec a)\cdot \vec w) \vec w\\
    \vec d ={}& \vec u + \text{\overrightharp{$\vec{ud}$}} = \vec u + \text{\overrightharp{$\vec{cu}$}} = \vec u + (\vec u - \vec c) = 2\vec u - \vec c\\
           ={}& 2(\vec a + ((\vec c -\vec a)\cdot \vec w) \vec w) - \vec c \qedhere
  \end{align*}
\end{proof}

\subsection{坐标变换}
\label{sec:coordinate-transform}

\begin{theorem}[点积与叉积是坐标变换下的不变量]
  欧氏空间中向量的点积与叉积与坐标系的选择无关，在任意坐标下其点积(或叉积)都为同一个值(或向量)。
\end{theorem}
\begin{proof}[提示]
  \color{red}待补充。
\end{proof}

\begin{example}[角平分线]
  $\triangle ABC$，记三顶点坐标为$a,b,c$，求顶点$C$的角平分线与对边交点$D$的坐标$d$。

  由角平分线性质，有
  \begin{align*}
    \frac{AD}{DB}=\frac{AC}{BC}=\frac{\left|\vec a-\vec c\right|}{\left|\vec b-\vec c\right|}
    \implies
    \frac{AD}{AB} = \frac{\left|\vec a-\vec c\right|}{\left|\vec a-\vec c\right| + \left|\vec b-\vec c\right|}
  \end{align*}
  从而
  \begin{align*}
    \vec d={}\vec a + \text{\overrightharp{$\vec{ad}$}} = \vec a + \frac{\left|\vec a-\vec c\right|}{\left|\vec a-\vec c\right| + \left|\vec b-\vec c\right|}(\vec b - \vec a)
    ={} \frac{\left|\vec b-\vec c\right|\cdot \vec a + \left|\vec a-\vec c\right|\cdot \vec b}
              {\left|\vec a-\vec c\right| + \left|\vec b-\vec c\right|}
  \end{align*}
\end{example}
